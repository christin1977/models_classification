{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1339125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, csv\n",
    "import pandas as pd\n",
    "import csv, re, time\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "import math\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e28b3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation du fichier company\n",
    "\n",
    "url_company = 'C:/Users/chris/OneDrive/Bureau/PrescriptiveFS/webscrap/03032024/Company-2024-03-03.csv'\n",
    "data_company = pd.read_csv(url_company)\n",
    "\n",
    "\n",
    "# creation du fichier keyword\n",
    "\n",
    "url_GoogleSearchKeyword = 'C:/Users/chris/OneDrive/Bureau/PrescriptiveFS/webscrap/03032024/GoogleSearchKeyword-2024-03-03.csv'\n",
    "data_GoogleSearchKeyword = pd.read_csv(url_GoogleSearchKeyword)\n",
    "\n",
    "# creation du fichier googleresults\n",
    "\n",
    "url_google_results = 'C:/Users/chris/OneDrive/Bureau/PrescriptiveFS/webscrap/03032024/GoogleSearchResult-2024-03-03.csv'\n",
    "data_google_results = pd.read_csv(url_google_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18e84cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>siren</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>country</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>ape</th>\n",
       "      <th>founded_date</th>\n",
       "      <th>turnover_2022</th>\n",
       "      <th>gouv_searched</th>\n",
       "      <th>gouv_street</th>\n",
       "      <th>gouv_city</th>\n",
       "      <th>gouv_postal_code</th>\n",
       "      <th>gouv_country</th>\n",
       "      <th>gouv_lat</th>\n",
       "      <th>gouv_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>847593225</td>\n",
       "      <td>AAA COIFFURE</td>\n",
       "      <td>AAA COIFFURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 RUE PAGANINI</td>\n",
       "      <td>NICE</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9602A</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>33300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rue Paganini</td>\n",
       "      <td>Nice</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.702199</td>\n",
       "      <td>7.263926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>331057406</td>\n",
       "      <td>ACA NEXIA</td>\n",
       "      <td>ACA NEXIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 RUE HENRI ROCHEFORT</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>75017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6920Z</td>\n",
       "      <td>1984-09-01</td>\n",
       "      <td>18602980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rue Henri Rochefort</td>\n",
       "      <td>Paris</td>\n",
       "      <td>75017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.882511</td>\n",
       "      <td>2.308276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>845298249</td>\n",
       "      <td>AEV AUTO ECOLE VEILLON</td>\n",
       "      <td>AUTO ECOLE VEILLON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 AVENUE VILLERMONT</td>\n",
       "      <td>NICE</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8553Z</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>244188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Avenue Villermont</td>\n",
       "      <td>Nice</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.709300</td>\n",
       "      <td>7.264297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>527</td>\n",
       "      <td>316473305</td>\n",
       "      <td>AGRI-POLE</td>\n",
       "      <td>AGRI-POLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUE SAINT VICTOR</td>\n",
       "      <td>VILLEFRANCHE-DE-ROUERGUE</td>\n",
       "      <td>34420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4661Z</td>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310</td>\n",
       "      <td>349638395</td>\n",
       "      <td>AIR CORSICA</td>\n",
       "      <td>CCM AIRLINES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAMPO DELL ORO</td>\n",
       "      <td>AJACCIO</td>\n",
       "      <td>20090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5110Z</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>130850508.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Campo Dell Oro</td>\n",
       "      <td>Ajaccio</td>\n",
       "      <td>20090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.929606</td>\n",
       "      <td>8.804378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      siren                    name          brand_name description  \\\n",
       "0  164  847593225            AAA COIFFURE        AAA COIFFURE         NaN   \n",
       "1  203  331057406               ACA NEXIA           ACA NEXIA         NaN   \n",
       "2  163  845298249  AEV AUTO ECOLE VEILLON  AUTO ECOLE VEILLON         NaN   \n",
       "3  527  316473305               AGRI-POLE           AGRI-POLE         NaN   \n",
       "4  310  349638395             AIR CORSICA        CCM AIRLINES         NaN   \n",
       "\n",
       "                  address                      city  postal_code country  \\\n",
       "0         11 RUE PAGANINI                      NICE         6000     NaN   \n",
       "1  31 RUE HENRI ROCHEFORT                     PARIS        75017     NaN   \n",
       "2    11 AVENUE VILLERMONT                      NICE         6000     NaN   \n",
       "3        RUE SAINT VICTOR  VILLEFRANCHE-DE-ROUERGUE        34420     NaN   \n",
       "4          CAMPO DELL ORO                   AJACCIO        20090     NaN   \n",
       "\n",
       "   phone  ...    ape  founded_date turnover_2022 gouv_searched  \\\n",
       "0    NaN  ...  9602A    2019-01-15       33300.0           1.0   \n",
       "1    NaN  ...  6920Z    1984-09-01    18602980.0           1.0   \n",
       "2    NaN  ...  8553Z    2019-01-09      244188.0           1.0   \n",
       "3    NaN  ...  4661Z    1979-01-01           NaN           0.0   \n",
       "4    NaN  ...  5110Z    1990-01-01   130850508.0           1.0   \n",
       "\n",
       "           gouv_street gouv_city  gouv_postal_code  gouv_country   gouv_lat  \\\n",
       "0         Rue Paganini      Nice            6000.0           NaN  43.702199   \n",
       "1  Rue Henri Rochefort     Paris           75017.0           NaN  48.882511   \n",
       "2    Avenue Villermont      Nice            6000.0           NaN  43.709300   \n",
       "3                  NaN       NaN               NaN           NaN        NaN   \n",
       "4       Campo Dell Oro   Ajaccio           20090.0           NaN  41.929606   \n",
       "\n",
       "   gouv_lng  \n",
       "0  7.263926  \n",
       "1  2.308276  \n",
       "2  7.264297  \n",
       "3       NaN  \n",
       "4  8.804378  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16a53777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>siren</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>country</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>ape</th>\n",
       "      <th>founded_date</th>\n",
       "      <th>turnover_2022</th>\n",
       "      <th>gouv_searched</th>\n",
       "      <th>gouv_street</th>\n",
       "      <th>gouv_city</th>\n",
       "      <th>gouv_postal_code</th>\n",
       "      <th>gouv_country</th>\n",
       "      <th>gouv_lat</th>\n",
       "      <th>gouv_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>320</td>\n",
       "      <td>377550249</td>\n",
       "      <td>WAVESTONE</td>\n",
       "      <td>WAVESTONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100 TERRASSE BOIELDIEU</td>\n",
       "      <td>PUTEAUX</td>\n",
       "      <td>92800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6202A</td>\n",
       "      <td>1990-04-01</td>\n",
       "      <td>377647000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terrasse Boieldieu</td>\n",
       "      <td>Puteaux</td>\n",
       "      <td>92800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.889287</td>\n",
       "      <td>2.24075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      siren        name brand_name description  \\\n",
       "268  320  377550249   WAVESTONE  WAVESTONE         NaN   \n",
       "\n",
       "                    address     city  postal_code country  phone  ...    ape  \\\n",
       "268  100 TERRASSE BOIELDIEU  PUTEAUX        92800     NaN    NaN  ...  6202A   \n",
       "\n",
       "     founded_date turnover_2022 gouv_searched         gouv_street gouv_city  \\\n",
       "268    1990-04-01   377647000.0           1.0  Terrasse Boieldieu   Puteaux   \n",
       "\n",
       "     gouv_postal_code  gouv_country   gouv_lat gouv_lng  \n",
       "268           92800.0           NaN  48.889287  2.24075  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_company[data_company['id'] == 320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0e9652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>active</th>\n",
       "      <th>keyword</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>\"annonce\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>\"controverses\" OR \"problème\" OR \"litige\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>\"événement\" OR \"séminaire\" OR \"atelier\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>\"lancement de produit\" OR \"nouveau service\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  active                                      keyword  news\n",
       "0  116       1                                 \"actualités\"     0\n",
       "1  149       1                                    \"annonce\"     0\n",
       "2  154       1     \"controverses\" OR \"problème\" OR \"litige\"     0\n",
       "3  153       1      \"événement\" OR \"séminaire\" OR \"atelier\"     0\n",
       "4  151       1  \"lancement de produit\" OR \"nouveau service\"     0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_GoogleSearchKeyword.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "127f0c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search</th>\n",
       "      <th>company</th>\n",
       "      <th>google_results</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>116</td>\n",
       "      <td>545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-03 07:02:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>116</td>\n",
       "      <td>309</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>116</td>\n",
       "      <td>491</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>116</td>\n",
       "      <td>506</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>116</td>\n",
       "      <td>320</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  search  company                                     google_results  \\\n",
       "0  1999     116      545                                                NaN   \n",
       "1   372     116      309  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "2   371     116      491  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "3   370     116      506  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "4   369     116      320  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "\n",
       "          scraped_date  scraped  \n",
       "0  2024-03-03 07:02:38      NaN  \n",
       "1  2023-09-20 10:39:31      1.0  \n",
       "2  2023-09-20 10:39:27      1.0  \n",
       "3  2023-09-20 10:39:23      1.0  \n",
       "4  2023-09-20 10:39:24      1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_google_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77b8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = []\n",
    "SIRET_list = []\n",
    "\n",
    "# Itérer sur chaque ligne du DataFrame\n",
    "for index, occurrence in data_company.iterrows():\n",
    "    company = occurrence['id']  # Assurez-vous que 'id' est le nom correct de la colonne\n",
    "    SIRET = occurrence['siret']  # Assurez-vous que 'siret' est le nom correct de la colonne\n",
    "    company_list.append(company)\n",
    "    SIRET_list.append(SIRET)\n",
    "\n",
    "Id_SIRET = dict(zip(company_list, SIRET_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68457992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pk_search_list = []\n",
    "keyword_list = []\n",
    "\n",
    "# Itérer sur chaque ligne du DataFrame\n",
    "for index, occurrence in data_GoogleSearchKeyword.iterrows():\n",
    "    Pk_search = occurrence['id']\n",
    "    keyword = occurrence['keyword']\n",
    "    Pk_search_list.append(Pk_search)\n",
    "    keyword_list.append(keyword)\n",
    "\n",
    "Search_keyword = dict(zip(Pk_search_list, keyword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f68b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{116: '\"actualités\"',\n",
       " 149: '\"annonce\"',\n",
       " 154: '\"controverses\" OR \"problème\" OR \"litige\"',\n",
       " 153: '\"événement\" OR \"séminaire\" OR \"atelier\"',\n",
       " 151: '\"lancement de produit\" OR \"nouveau service\"',\n",
       " 152: '\"nomination\" OR \"départ\" OR \"nouveau dirigeant\"',\n",
       " 150: '\"partenariat\" OR \"collaboration\"'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Search_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069de15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modifie = []\n",
    "\n",
    "# Parcourir chaque élément du google search, créer un dictionnaire id (company) / SIRET / keyword / contenu\n",
    "\n",
    "for index, element in data_google_results.iterrows():\n",
    "    nouvel_element = {}\n",
    "    for cle, valeur in element.items():\n",
    "        if cle == 'company':\n",
    "            nouvel_element['SIRET'] = Id_SIRET[element['company']] # affecter le SIRET en fonction de la table company (Id)\n",
    "        elif cle == 'search':\n",
    "            nouvel_element['keyword'] = Search_keyword[element['search']]\n",
    "        else:\n",
    "            nouvel_element[cle] = valeur\n",
    "    data_modifie.append(nouvel_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1666b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modifie = pd.DataFrame(data_modifie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a241f71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>SIRET</th>\n",
       "      <th>google_results</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>408627354 00124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-03 07:02:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>34899155500353</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>30649449300050</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>31124863700804</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>37755024900041</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>1732</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>34963839500021</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>1731</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>31647330500035</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1730</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>84529824900028</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>1729</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>33105740600067</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>1728</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>84759322500018</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           keyword            SIRET  \\\n",
       "0     1999                      \"actualités\"  408627354 00124   \n",
       "1      372                      \"actualités\"   34899155500353   \n",
       "2      371                      \"actualités\"   30649449300050   \n",
       "3      370                      \"actualités\"   31124863700804   \n",
       "4      369                      \"actualités\"   37755024900041   \n",
       "...    ...                               ...              ...   \n",
       "1899  1732  \"partenariat\" OR \"collaboration\"   34963839500021   \n",
       "1900  1731  \"partenariat\" OR \"collaboration\"   31647330500035   \n",
       "1901  1730  \"partenariat\" OR \"collaboration\"   84529824900028   \n",
       "1902  1729  \"partenariat\" OR \"collaboration\"   33105740600067   \n",
       "1903  1728  \"partenariat\" OR \"collaboration\"   84759322500018   \n",
       "\n",
       "                                         google_results         scraped_date  \\\n",
       "0                                                   NaN  2024-03-03 07:02:38   \n",
       "1     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:31   \n",
       "2     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:27   \n",
       "3     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:23   \n",
       "4     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:24   \n",
       "...                                                 ...                  ...   \n",
       "1899  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:31   \n",
       "1900  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:30   \n",
       "1901  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:47   \n",
       "1902  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:37   \n",
       "1903  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:36   \n",
       "\n",
       "      scraped  \n",
       "0         NaN  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "...       ...  \n",
       "1899      1.0  \n",
       "1900      1.0  \n",
       "1901      1.0  \n",
       "1902      1.0  \n",
       "1903      1.0  \n",
       "\n",
       "[1904 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee593cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"actualités\"\n",
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"annonce\"\n",
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"controverses\" OR \"problème\" OR \"litige\"\n",
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"événement\" OR \"séminaire\" OR \"atelier\"\n",
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"lancement de produit\" OR \"nouveau service\"\n",
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"nomination\" OR \"départ\" OR \"nouveau dirigeant\"\n",
      "Erreur : json_str n'est pas une chaîne. SIRET: 408627354 00124, Keyword: \"partenariat\" OR \"collaboration\"\n"
     ]
    }
   ],
   "source": [
    "def extraire_donnees(json_str, siret, keyword):\n",
    "    try:\n",
    "        # Assurez-vous que json_str est une chaîne\n",
    "        if not isinstance(json_str, str):\n",
    "            print(f\"Erreur : json_str n'est pas une chaîne. SIRET: {siret}, Keyword: {keyword}\")\n",
    "            return []\n",
    "\n",
    "        # Charger la chaîne JSON en dictionnaire\n",
    "        data = json.loads(json_str)\n",
    "        results = []\n",
    "        \n",
    "        # Itération sur les résultats organiques\n",
    "        for result in data.get('organic_results', []):\n",
    "            res_dict = {\n",
    "                'siret': siret,\n",
    "                'keyword': keyword,\n",
    "                'url': result.get('url', ''),\n",
    "                'title': result.get('title', ''),\n",
    "                'domain': result.get('domain', ''),\n",
    "                'description': result.get('description', ''),\n",
    "                'displayed_url': result.get('displayed_url', '')\n",
    "            }\n",
    "            if isinstance(result.get('sitelinks'), dict):\n",
    "                res_dict['sitelinks'] = result.get('sitelinks', {}).get('expanded', [])\n",
    "            else:\n",
    "                res_dict['sitelinks'] = []\n",
    "            results.append(res_dict)\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction: {e}, siret: {siret}, keyword: {keyword}\")\n",
    "        return []\n",
    "    \n",
    "resultats_extraits = []\n",
    "\n",
    "# Itérer sur chaque ligne du DataFrame data_modifie\n",
    "for idx, row in data_modifie.iterrows():\n",
    "    # Extraire les données organiques, le siret et le mot-clé pour chaque ligne\n",
    "    resultats_temp = extraire_donnees(row['google_results'], row['SIRET'], row['keyword'])\n",
    "    # Ajouter les résultats à la liste principale\n",
    "    resultats_extraits.extend(resultats_temp)\n",
    "\n",
    "# Convertir la liste des résultats extraits en un nouveau DataFrame\n",
    "detail_google_search = pd.DataFrame(resultats_extraits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a53f7aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siret</th>\n",
       "      <th>keyword</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "      <th>description</th>\n",
       "      <th>displayed_url</th>\n",
       "      <th>sitelinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>https://www.nicematin.com/conso-shopping/le-pl...</td>\n",
       "      <td>Le plus grand Zara de la région Sud a ouvert c...</td>\n",
       "      <td>www.nicematin.com</td>\n",
       "      <td>May 4, 2023 — Nice-Matin. Se connecter · Abonn...</td>\n",
       "      <td>https://www.nicematin.com › le-plu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>https://nicepresse.com/le-plus-grand-zara-de-t...</td>\n",
       "      <td>Le plus grand Zara de tout le Sud-Est bientôt ...</td>\n",
       "      <td>nicepresse.com</td>\n",
       "      <td>Oct 31, 2022 — Nice-Presse : actualités et inf...</td>\n",
       "      <td>https://nicepresse.com › le-plus-gra...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>https://actu.fr/provence-alpes-cote-d-azur/nic...</td>\n",
       "      <td>Nice. Pourquoi y avait-il une grosse file d'at...</td>\n",
       "      <td>actu.fr</td>\n",
       "      <td>Nov 25, 2022 — Dernières actualités. Actu Nice...</td>\n",
       "      <td>https://actu.fr › nice_06088 › nice-...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>https://actu.fr/provence-alpes-cote-d-azur/sai...</td>\n",
       "      <td>Près de Nice, CAP 3000 annonce de nouvelles bo...</td>\n",
       "      <td>actu.fr</td>\n",
       "      <td>Jan 19, 2023 — L'un des plus grands Zara de Fr...</td>\n",
       "      <td>https://actu.fr › pres-de-nice-cap-30...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualités\"</td>\n",
       "      <td>https://www.lefigaro.fr/tag/zara</td>\n",
       "      <td>Zara : dernières actualités et vidéos</td>\n",
       "      <td>www.lefigaro.fr</td>\n",
       "      <td>Les dernières actualités sur Zara.</td>\n",
       "      <td>https://www.lefigaro.fr › tag › zara</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13930</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=9QIdYbTIKQAC&amp;...</td>\n",
       "      <td>Le Mémorial diplomatique</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... AAA Vient de Paraitre chez PAUL OLLENDORFF...</td>\n",
       "      <td>https://books.google.fr › books</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13931</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=PbKXBAAAQBAJ&amp;...</td>\n",
       "      <td>Michelin Green Guide France - Google Books Result</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... collaboration with Coysevox and Tuby. In t...</td>\n",
       "      <td>https://books.google.fr › books</td>\n",
       "      <td>[{'link': '/search?num=100&amp;sca_esv=566872717&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13932</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=CjiXEAAAQBAJ&amp;...</td>\n",
       "      <td>Sekiro: La seconde vie des Souls - Google Book...</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... partenariat avec Activision en surprend – ...</td>\n",
       "      <td>https://books.google.fr › books</td>\n",
       "      <td>[{'link': '/search?num=100&amp;sca_esv=566872717&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13933</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=qZZ-CwAAQBAJ&amp;...</td>\n",
       "      <td>Robert Trent Jones Golf Trail: Its History and...</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... collaboration between the City of Montgome...</td>\n",
       "      <td>https://books.google.fr › books</td>\n",
       "      <td>[{'link': '/search?num=100&amp;sca_esv=566872717&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=PYY9AQAAMAAJ&amp;...</td>\n",
       "      <td>Bulletin du Comité de l'Asie française</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... coiffure sur leur tête rasée un volumineux...</td>\n",
       "      <td>https://books.google.fr › books</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13935 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                siret                           keyword  \\\n",
       "0      34899155500353                      \"actualités\"   \n",
       "1      34899155500353                      \"actualités\"   \n",
       "2      34899155500353                      \"actualités\"   \n",
       "3      34899155500353                      \"actualités\"   \n",
       "4      34899155500353                      \"actualités\"   \n",
       "...               ...                               ...   \n",
       "13930  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13931  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13932  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13933  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13934  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.nicematin.com/conso-shopping/le-pl...   \n",
       "1      https://nicepresse.com/le-plus-grand-zara-de-t...   \n",
       "2      https://actu.fr/provence-alpes-cote-d-azur/nic...   \n",
       "3      https://actu.fr/provence-alpes-cote-d-azur/sai...   \n",
       "4                       https://www.lefigaro.fr/tag/zara   \n",
       "...                                                  ...   \n",
       "13930  https://books.google.fr/books?id=9QIdYbTIKQAC&...   \n",
       "13931  https://books.google.fr/books?id=PbKXBAAAQBAJ&...   \n",
       "13932  https://books.google.fr/books?id=CjiXEAAAQBAJ&...   \n",
       "13933  https://books.google.fr/books?id=qZZ-CwAAQBAJ&...   \n",
       "13934  https://books.google.fr/books?id=PYY9AQAAMAAJ&...   \n",
       "\n",
       "                                                   title             domain  \\\n",
       "0      Le plus grand Zara de la région Sud a ouvert c...  www.nicematin.com   \n",
       "1      Le plus grand Zara de tout le Sud-Est bientôt ...     nicepresse.com   \n",
       "2      Nice. Pourquoi y avait-il une grosse file d'at...            actu.fr   \n",
       "3      Près de Nice, CAP 3000 annonce de nouvelles bo...            actu.fr   \n",
       "4                  Zara : dernières actualités et vidéos    www.lefigaro.fr   \n",
       "...                                                  ...                ...   \n",
       "13930                           Le Mémorial diplomatique    books.google.fr   \n",
       "13931  Michelin Green Guide France - Google Books Result    books.google.fr   \n",
       "13932  Sekiro: La seconde vie des Souls - Google Book...    books.google.fr   \n",
       "13933  Robert Trent Jones Golf Trail: Its History and...    books.google.fr   \n",
       "13934             Bulletin du Comité de l'Asie française    books.google.fr   \n",
       "\n",
       "                                             description  \\\n",
       "0      May 4, 2023 — Nice-Matin. Se connecter · Abonn...   \n",
       "1      Oct 31, 2022 — Nice-Presse : actualités et inf...   \n",
       "2      Nov 25, 2022 — Dernières actualités. Actu Nice...   \n",
       "3      Jan 19, 2023 — L'un des plus grands Zara de Fr...   \n",
       "4                     Les dernières actualités sur Zara.   \n",
       "...                                                  ...   \n",
       "13930  ... AAA Vient de Paraitre chez PAUL OLLENDORFF...   \n",
       "13931  ... collaboration with Coysevox and Tuby. In t...   \n",
       "13932  ... partenariat avec Activision en surprend – ...   \n",
       "13933  ... collaboration between the City of Montgome...   \n",
       "13934  ... coiffure sur leur tête rasée un volumineux...   \n",
       "\n",
       "                                  displayed_url  \\\n",
       "0         https://www.nicematin.com › le-plu...   \n",
       "1       https://nicepresse.com › le-plus-gra...   \n",
       "2       https://actu.fr › nice_06088 › nice-...   \n",
       "3      https://actu.fr › pres-de-nice-cap-30...   \n",
       "4          https://www.lefigaro.fr › tag › zara   \n",
       "...                                         ...   \n",
       "13930           https://books.google.fr › books   \n",
       "13931           https://books.google.fr › books   \n",
       "13932           https://books.google.fr › books   \n",
       "13933           https://books.google.fr › books   \n",
       "13934           https://books.google.fr › books   \n",
       "\n",
       "                                               sitelinks  \n",
       "0                                                     []  \n",
       "1                                                     []  \n",
       "2                                                     []  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "13930                                                 []  \n",
       "13931  [{'link': '/search?num=100&sca_esv=566872717&g...  \n",
       "13932  [{'link': '/search?num=100&sca_esv=566872717&g...  \n",
       "13933  [{'link': '/search?num=100&sca_esv=566872717&g...  \n",
       "13934                                                 []  \n",
       "\n",
       "[13935 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_google_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2450e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez des colonnes pour le résumé et la date dans le DataFrame\n",
    "detail_google_search['resume'] = pd.NA\n",
    "detail_google_search['date'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1282e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Découper le DataFrame en sous-ensembles en tenant compte des changements de SIRET\n",
    "start_idx = 0  # Index de départ pour la tranche actuelle\n",
    "for i in range(taille_chunk, len(detail_google_search_sorted) + taille_chunk, taille_chunk):\n",
    "    # Trouver la fin de la tranche en s'assurant que tous les enregistrements d'un SIRET sont ensemble\n",
    "    # Si on n'est pas à la fin du DataFrame\n",
    "    if i < len(detail_google_search_sorted):\n",
    "        while (i < len(detail_google_search_sorted) and \n",
    "               detail_google_search_sorted.iloc[i - 1]['siret'] == detail_google_search_sorted.iloc[i]['siret']):\n",
    "            i += 1  # Déplacer l'index de fin jusqu'à ce qu'on trouve un nouveau SIRET\n",
    "    \n",
    "    # Découper le DataFrame jusqu'à cet indice\n",
    "    dfs.append(detail_google_search_sorted[start_idx:i])\n",
    "    \n",
    "    # Mettre à jour l'index de départ pour la prochaine tranche\n",
    "    start_idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b88b6728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tranches créées : 5\n",
      "tranche 1 : 2795\n",
      "tranche 2 : 2932\n",
      "tranche 3 : 2639\n",
      "tranche 4 : 2784\n",
      "tranche 5 : 2785\n",
      "total: 13935\n"
     ]
    }
   ],
   "source": [
    "nombre_tranches = len(dfs)-1\n",
    "print(f\"Nombre de tranches créées : {nombre_tranches}\")\n",
    "print(f\"tranche 1 : {len(dfs[1])}\")\n",
    "print(f\"tranche 2 : {len(dfs[2])}\")\n",
    "print(f\"tranche 3 : {len(dfs[3])}\")\n",
    "print(f\"tranche 4 : {len(dfs[4])}\")\n",
    "print(f\"tranche 5 : {len(dfs[5])}\")\n",
    "print(f\"total: {len(dfs[1])+len(dfs[2])+len(dfs[3])+len(dfs[4])+len(dfs[5])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0d4fd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_et_resume(url):\n",
    "    attempts = 0\n",
    "    while attempts < 1:  # une tentative\n",
    "        try:\n",
    "            # Effectuer une requête GET sur le site\n",
    "            response = requests.get(url, timeout=10)  # Augmentez le timeout si nécessaire\n",
    "            # Créer un objet BeautifulSoup pour analyser le HTML\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extraire le texte souhaité, par exemple, tous les paragraphes\n",
    "            text = ' '.join(p.text for p in soup.find_all('p'))\n",
    "\n",
    "            # Recherche de la date dans les métadonnées\n",
    "            meta_date = soup.find('meta', {'property': 'article:published_time'})\n",
    "            if meta_date:\n",
    "                date = meta_date['content']\n",
    "            else:\n",
    "                # Ajoutez le nouveau motif pour les dates avec mois en lettres\n",
    "                date_patterns = [\n",
    "                    r'\\b\\d{4}-\\d{2}-\\d{2}\\b',\n",
    "                    r'\\b\\d{2}/\\d{2}/\\d{4}\\b',\n",
    "                    r'\\b\\d{2}-\\d{2}-\\d{4}\\b',\n",
    "                    # Motif pour le format \"14 octobre 2023\" ou \"14 Octobre 2023\"\n",
    "                    r'\\b\\d{1,2}\\s(?:janvier|février|mars|avril|mai|juin|juillet|août|septembre|octobre|novembre|décembre)\\s\\d{4}\\b',\n",
    "                    r'\\b\\d{1,2}\\s(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}\\b'\n",
    "                ]\n",
    "                date = 'Date non trouvée'\n",
    "                for pattern in date_patterns:\n",
    "                    match = re.search(pattern, text, re.IGNORECASE)  # Utiliser IGNORECASE pour ne pas se soucier de la casse\n",
    "                    if match:\n",
    "                        date = match.group()\n",
    "                        break\n",
    "\n",
    "            # Création d'un résumé du texte\n",
    "            parser = PlaintextParser.from_string(text, Tokenizer('french'))\n",
    "            summarizer = Summarizer()\n",
    "            resume_text = ' '.join(str(sentence) for sentence in summarizer(parser.document, 10))\n",
    "            return resume_text, date\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            attempts += 1\n",
    "            time.sleep(5)  # Délai entre les tentatives\n",
    "    \n",
    "    # Retourner None si toutes les tentatives échouent\n",
    "    return None, None\n",
    "\n",
    "def analyze_sentiment(sentence):\n",
    "    analysis = TextBlob(sentence)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positif'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutre'\n",
    "    else:\n",
    "        return 'Négatif'\n",
    "    \n",
    "# Fonction pour convertir les sentiments en poids\n",
    "def sentiment_to_weight(sentiment):\n",
    "    weights = {'Positif': 1, 'Neutre': 0, 'Négatif': -1}\n",
    "    return weights.get(sentiment, 0)  # Retourne 0 si le sentiment n'est pas reconnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386412a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traiter_dataframe(df):\n",
    "    # fonction de parralelisation\n",
    "    \n",
    "    print(f\"Traitement du DataFrame de taille {len(df)}\")\n",
    "    \n",
    "    # Réinitialise l'index du DataFrame pour une itération propre (df_index(drop=True) devrait être df.reset_index(drop=True) \n",
    "    # pour fonctionner correctement).\n",
    "    df = df_index(drop=True)\n",
    "    \n",
    "    # Calcul du total des lignes et du point de contrôle pour suivre la progression du traitement, en découpant le DataFrame en dix segments (10 % chacun) \n",
    "    # pour les rapports d'avancement.\n",
    "    total_lignes = len(df)\n",
    "    print(total_lignes)\n",
    "    pourcent = total_lignes / 10\n",
    "    compteur=0\n",
    "    \n",
    "    # Itère sur chaque ligne du DataFrame pour exécuter scraper_et_resume sur l'URL de chaque ligne. \n",
    "    # Met à jour le DataFrame avec les nouveaux résumés et dates récupérés, à condition que le résumé ne soit pas vide.\n",
    "    for index, row in df.iterrows():\n",
    "    try:\n",
    "        resume, date = scraper_et_resume(row['url'])\n",
    "        # Vérifiez si le résumé est vide avant de mettre à jour le DataFrame\n",
    "        if resume:  # Si 'resume' n'est pas vide\n",
    "            df.at[index, 'resume'] = resume\n",
    "            df.at[index, 'date'] = date\n",
    "        else:  \n",
    "            print(f\"Contenu vide pour l'URL {row['url']} à la ligne {index}, pas de mise à jour.\")\n",
    "            continue  # Passe à l'itération suivante sans mettre à jour les valeurs dans le DataFrame\n",
    "    # Gère les exceptions qui peuvent survenir pendant le processus de scraping, permettant à la boucle de continuer même en cas d'erreur.        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de la ligne {index}: {e}\")\n",
    "        continue  # Passe à l'itération suivante en cas d'erreur\n",
    "    \n",
    "    print(f\"Avancement: {math.ceil((compteur / total_lignes) * 100)}% terminé.\")\n",
    "    compteur+=1\n",
    "    \n",
    "    # Supprime les lignes où la colonne 'date' est NaN après le scraping pour assurer l'intégrité des données et remplace \n",
    "    # les chaînes \"Date non trouvée\" par NaN, puis convertit les chaînes de date restantes en objets datetime, \n",
    "    #en gérant les erreurs et en supprimant le fuseau horaire pour uniformité.\n",
    "    df = df.dropna(subset=['date'])\n",
    "\n",
    "    # Remplacer \"Date non trouvée\" par NaN puis convertir les chaînes de date en objets datetime\n",
    "    df['date'] = df['date'].replace('Date non trouvée', pd.NA)\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "\n",
    "    # Obtenir la date du jour en UTC pour garder la cohérence avec les autres dates\n",
    "    date_du_jour = pd.Timestamp('now', tz='UTC')\n",
    "\n",
    "    # Remplacer les valeurs NaN par la date du jour en format UTC\n",
    "    df['date'] = df['date'].fillna(date_du_jour)\n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "\n",
    "    # Extraire l'année de la colonne de date\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Appliquer la fonction analyze_sentiment à chaque résumé dans le DataFrame\n",
    "    df['sentiment'] = df['resume'].apply(analyze_sentiment)\n",
    "    \n",
    "    # Convertir les dates en datetime et extraire l'année\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    # Appliquer la fonction pour convertir les sentiments en poids\n",
    "    df['sentiment_weight'] = df['sentiment'].apply(sentiment_to_weight)\n",
    "\n",
    "    # Calculer la moyenne pondérée des sentiments par année\n",
    "    weighted_average_by_year = df.groupby('year')['sentiment_weight'].mean()\n",
    "    \n",
    "    # Calculer la moyenne pondérée des sentiments par année et par SIRET\n",
    "    grouped = df.groupby(['siret', 'year'])['sentiment_weight'].mean().reset_index()\n",
    "\n",
    "    # Pivoter pour obtenir les années en colonnes et les SIRETs en lignes\n",
    "    pivot_table = grouped.pivot(index='siret', columns='year', values='sentiment_weight')\n",
    "\n",
    "    # Renommer les colonnes pour le format souhaité\n",
    "    pivot_table.columns = [f'sentiment weight an{year}' for year in pivot_table.columns]\n",
    "\n",
    "    # Réinitialiser l'index pour obtenir 'siret' comme une colonne\n",
    "    final_output = pivot_table.reset_index()\n",
    "\n",
    "    # Afficher le DataFrame final\n",
    "    print(final_output)\n",
    "    \n",
    "        return df, final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de ThreadPoolExecutor pour paralléliser le traitement\n",
    "\n",
    "dfs_adaptes = []  # Liste pour stocker tous les DataFrames adaptés\n",
    "dfs_final_output = []  # Liste pour stocker tous les DataFrames final_output\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Planifier l'exécution de la fonction de traitement pour chaque sous-DataFrame\n",
    "    futures = [executor.submit(traiter_dataframe, df) for df in dfs]\n",
    "\n",
    "    # Attendre que tous les futurs soient terminés et recueillir les résultats\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        df_adapte, final_out = future.result()\n",
    "        dfs_adaptes.append(df_adapte)\n",
    "        dfs_final_output.append(final_out)\n",
    "\n",
    "# Fusionner tous les DataFrames adaptés en un seul\n",
    "data_google_search = pd.concat(dfs_adaptes)\n",
    "\n",
    "# Fusionner tous les final_output en un seul\n",
    "global_final_output = pd.concat(dfs_final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02670178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir la date actuelle\n",
    "date_actuelle = datetime.now().strftime('%Y-%m-%d')  # Formate la date comme \"AAAA-MM-JJ\"\n",
    "\n",
    "# Créer le nom du fichier avec la date\n",
    "nom_fichier = f\"search_Google_{date_actuelle}_actu_resumé.csv\"\n",
    "\n",
    "# Exporter le DataFrame en CSV\n",
    "data_google_search.to_csv(nom_fichier, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#referentiel base source\n",
    "source_entreprise=pd.read_csv('base_source_enrichie.csv', encoding='utf-8', sep=',', on_bad_lines='skip')\n",
    "source_entreprise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55928f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les DataFrames  base enrichie et final output sur la colonne 'siret'\n",
    "df_enrichie = pd.merge(source_entreprise, global_final_output, on='siret', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa709da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter le DataFrame en CSV\n",
    "nom-fichier='base_source_enrichie.csv'\n",
    "df_enrichie.to_csv(nom_fichier, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c48743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
