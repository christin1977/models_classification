{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1339125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, csv\n",
    "import pandas as pd\n",
    "import csv, re, time\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "import math\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e28b3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation du fichier company\n",
    "\n",
    "url_company = 'C:/Users/chris/OneDrive/Bureau/PrescriptiveFS/webscrap/03032024/Company-2024-03-03.csv'\n",
    "data_company = pd.read_csv(url_company)\n",
    "\n",
    "\n",
    "# creation du fichier keyword\n",
    "\n",
    "url_GoogleSearchKeyword = 'C:/Users/chris/OneDrive/Bureau/PrescriptiveFS/webscrap/03032024/GoogleSearchKeyword-2024-03-03.csv'\n",
    "data_GoogleSearchKeyword = pd.read_csv(url_GoogleSearchKeyword)\n",
    "\n",
    "# creation du fichier googleresults\n",
    "\n",
    "url_google_results = 'C:/Users/chris/OneDrive/Bureau/PrescriptiveFS/webscrap/03032024/GoogleSearchResult-2024-03-03.csv'\n",
    "data_google_results = pd.read_csv(url_google_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18e84cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>siren</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>country</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>ape</th>\n",
       "      <th>founded_date</th>\n",
       "      <th>turnover_2022</th>\n",
       "      <th>gouv_searched</th>\n",
       "      <th>gouv_street</th>\n",
       "      <th>gouv_city</th>\n",
       "      <th>gouv_postal_code</th>\n",
       "      <th>gouv_country</th>\n",
       "      <th>gouv_lat</th>\n",
       "      <th>gouv_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>847593225</td>\n",
       "      <td>AAA COIFFURE</td>\n",
       "      <td>AAA COIFFURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 RUE PAGANINI</td>\n",
       "      <td>NICE</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9602A</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>33300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rue Paganini</td>\n",
       "      <td>Nice</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.702199</td>\n",
       "      <td>7.263926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>331057406</td>\n",
       "      <td>ACA NEXIA</td>\n",
       "      <td>ACA NEXIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 RUE HENRI ROCHEFORT</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>75017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6920Z</td>\n",
       "      <td>1984-09-01</td>\n",
       "      <td>18602980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rue Henri Rochefort</td>\n",
       "      <td>Paris</td>\n",
       "      <td>75017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.882511</td>\n",
       "      <td>2.308276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>845298249</td>\n",
       "      <td>AEV AUTO ECOLE VEILLON</td>\n",
       "      <td>AUTO ECOLE VEILLON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 AVENUE VILLERMONT</td>\n",
       "      <td>NICE</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8553Z</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>244188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Avenue Villermont</td>\n",
       "      <td>Nice</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.709300</td>\n",
       "      <td>7.264297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>527</td>\n",
       "      <td>316473305</td>\n",
       "      <td>AGRI-POLE</td>\n",
       "      <td>AGRI-POLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUE SAINT VICTOR</td>\n",
       "      <td>VILLEFRANCHE-DE-ROUERGUE</td>\n",
       "      <td>34420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4661Z</td>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310</td>\n",
       "      <td>349638395</td>\n",
       "      <td>AIR CORSICA</td>\n",
       "      <td>CCM AIRLINES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAMPO DELL ORO</td>\n",
       "      <td>AJACCIO</td>\n",
       "      <td>20090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5110Z</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>130850508.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Campo Dell Oro</td>\n",
       "      <td>Ajaccio</td>\n",
       "      <td>20090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.929606</td>\n",
       "      <td>8.804378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      siren                    name          brand_name description  \\\n",
       "0  164  847593225            AAA COIFFURE        AAA COIFFURE         NaN   \n",
       "1  203  331057406               ACA NEXIA           ACA NEXIA         NaN   \n",
       "2  163  845298249  AEV AUTO ECOLE VEILLON  AUTO ECOLE VEILLON         NaN   \n",
       "3  527  316473305               AGRI-POLE           AGRI-POLE         NaN   \n",
       "4  310  349638395             AIR CORSICA        CCM AIRLINES         NaN   \n",
       "\n",
       "                  address                      city  postal_code country  \\\n",
       "0         11 RUE PAGANINI                      NICE         6000     NaN   \n",
       "1  31 RUE HENRI ROCHEFORT                     PARIS        75017     NaN   \n",
       "2    11 AVENUE VILLERMONT                      NICE         6000     NaN   \n",
       "3        RUE SAINT VICTOR  VILLEFRANCHE-DE-ROUERGUE        34420     NaN   \n",
       "4          CAMPO DELL ORO                   AJACCIO        20090     NaN   \n",
       "\n",
       "   phone  ...    ape  founded_date turnover_2022 gouv_searched  \\\n",
       "0    NaN  ...  9602A    2019-01-15       33300.0           1.0   \n",
       "1    NaN  ...  6920Z    1984-09-01    18602980.0           1.0   \n",
       "2    NaN  ...  8553Z    2019-01-09      244188.0           1.0   \n",
       "3    NaN  ...  4661Z    1979-01-01           NaN           0.0   \n",
       "4    NaN  ...  5110Z    1990-01-01   130850508.0           1.0   \n",
       "\n",
       "           gouv_street gouv_city  gouv_postal_code  gouv_country   gouv_lat  \\\n",
       "0         Rue Paganini      Nice            6000.0           NaN  43.702199   \n",
       "1  Rue Henri Rochefort     Paris           75017.0           NaN  48.882511   \n",
       "2    Avenue Villermont      Nice            6000.0           NaN  43.709300   \n",
       "3                  NaN       NaN               NaN           NaN        NaN   \n",
       "4       Campo Dell Oro   Ajaccio           20090.0           NaN  41.929606   \n",
       "\n",
       "   gouv_lng  \n",
       "0  7.263926  \n",
       "1  2.308276  \n",
       "2  7.264297  \n",
       "3       NaN  \n",
       "4  8.804378  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16a53777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>siren</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>country</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>ape</th>\n",
       "      <th>founded_date</th>\n",
       "      <th>turnover_2022</th>\n",
       "      <th>gouv_searched</th>\n",
       "      <th>gouv_street</th>\n",
       "      <th>gouv_city</th>\n",
       "      <th>gouv_postal_code</th>\n",
       "      <th>gouv_country</th>\n",
       "      <th>gouv_lat</th>\n",
       "      <th>gouv_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>320</td>\n",
       "      <td>377550249</td>\n",
       "      <td>WAVESTONE</td>\n",
       "      <td>WAVESTONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100 TERRASSE BOIELDIEU</td>\n",
       "      <td>PUTEAUX</td>\n",
       "      <td>92800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6202A</td>\n",
       "      <td>1990-04-01</td>\n",
       "      <td>377647000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terrasse Boieldieu</td>\n",
       "      <td>Puteaux</td>\n",
       "      <td>92800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.889287</td>\n",
       "      <td>2.24075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      siren        name brand_name description  \\\n",
       "268  320  377550249   WAVESTONE  WAVESTONE         NaN   \n",
       "\n",
       "                    address     city  postal_code country  phone  ...    ape  \\\n",
       "268  100 TERRASSE BOIELDIEU  PUTEAUX        92800     NaN    NaN  ...  6202A   \n",
       "\n",
       "     founded_date turnover_2022 gouv_searched         gouv_street gouv_city  \\\n",
       "268    1990-04-01   377647000.0           1.0  Terrasse Boieldieu   Puteaux   \n",
       "\n",
       "     gouv_postal_code  gouv_country   gouv_lat gouv_lng  \n",
       "268           92800.0           NaN  48.889287  2.24075  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_company[data_company['id'] == 320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0e9652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>active</th>\n",
       "      <th>keyword</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>\"annonce\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>\"controverses\" OR \"problÃ¨me\" OR \"litige\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Ã©vÃ©nement\" OR \"sÃ©minaire\" OR \"atelier\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>\"lancement de produit\" OR \"nouveau service\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  active                                      keyword  news\n",
       "0  116       1                                 \"actualitÃ©s\"     0\n",
       "1  149       1                                    \"annonce\"     0\n",
       "2  154       1     \"controverses\" OR \"problÃ¨me\" OR \"litige\"     0\n",
       "3  153       1      \"Ã©vÃ©nement\" OR \"sÃ©minaire\" OR \"atelier\"     0\n",
       "4  151       1  \"lancement de produit\" OR \"nouveau service\"     0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_GoogleSearchKeyword.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "127f0c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search</th>\n",
       "      <th>company</th>\n",
       "      <th>google_results</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>116</td>\n",
       "      <td>545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-03 07:02:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>116</td>\n",
       "      <td>309</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>116</td>\n",
       "      <td>491</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>116</td>\n",
       "      <td>506</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>116</td>\n",
       "      <td>320</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  search  company                                     google_results  \\\n",
       "0  1999     116      545                                                NaN   \n",
       "1   372     116      309  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "2   371     116      491  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "3   370     116      506  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "4   369     116      320  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...   \n",
       "\n",
       "          scraped_date  scraped  \n",
       "0  2024-03-03 07:02:38      NaN  \n",
       "1  2023-09-20 10:39:31      1.0  \n",
       "2  2023-09-20 10:39:27      1.0  \n",
       "3  2023-09-20 10:39:23      1.0  \n",
       "4  2023-09-20 10:39:24      1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_google_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77b8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = []\n",
    "SIRET_list = []\n",
    "\n",
    "# ItÃ©rer sur chaque ligne du DataFrame\n",
    "for index, occurrence in data_company.iterrows():\n",
    "    company = occurrence['id']  # Assurez-vous que 'id' est le nom correct de la colonne\n",
    "    SIRET = occurrence['siret']  # Assurez-vous que 'siret' est le nom correct de la colonne\n",
    "    company_list.append(company)\n",
    "    SIRET_list.append(SIRET)\n",
    "\n",
    "Id_SIRET = dict(zip(company_list, SIRET_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68457992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pk_search_list = []\n",
    "keyword_list = []\n",
    "\n",
    "# ItÃ©rer sur chaque ligne du DataFrame\n",
    "for index, occurrence in data_GoogleSearchKeyword.iterrows():\n",
    "    Pk_search = occurrence['id']\n",
    "    keyword = occurrence['keyword']\n",
    "    Pk_search_list.append(Pk_search)\n",
    "    keyword_list.append(keyword)\n",
    "\n",
    "Search_keyword = dict(zip(Pk_search_list, keyword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f68b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{116: '\"actualitÃ©s\"',\n",
       " 149: '\"annonce\"',\n",
       " 154: '\"controverses\" OR \"problÃ¨me\" OR \"litige\"',\n",
       " 153: '\"Ã©vÃ©nement\" OR \"sÃ©minaire\" OR \"atelier\"',\n",
       " 151: '\"lancement de produit\" OR \"nouveau service\"',\n",
       " 152: '\"nomination\" OR \"dÃ©part\" OR \"nouveau dirigeant\"',\n",
       " 150: '\"partenariat\" OR \"collaboration\"'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Search_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069de15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modifie = []\n",
    "\n",
    "# Parcourir chaque Ã©lÃ©ment du google search, crÃ©er un dictionnaire id (company) / SIRET / keyword / contenu\n",
    "\n",
    "for index, element in data_google_results.iterrows():\n",
    "    nouvel_element = {}\n",
    "    for cle, valeur in element.items():\n",
    "        if cle == 'company':\n",
    "            nouvel_element['SIRET'] = Id_SIRET[element['company']] # affecter le SIRET en fonction de la table company (Id)\n",
    "        elif cle == 'search':\n",
    "            nouvel_element['keyword'] = Search_keyword[element['search']]\n",
    "        else:\n",
    "            nouvel_element[cle] = valeur\n",
    "    data_modifie.append(nouvel_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1666b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modifie = pd.DataFrame(data_modifie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a241f71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>SIRET</th>\n",
       "      <th>google_results</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>408627354 00124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-03 07:02:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>34899155500353</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>30649449300050</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>31124863700804</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>37755024900041</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:39:24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>1732</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>34963839500021</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>1731</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>31647330500035</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1730</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>84529824900028</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>1729</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>33105740600067</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>1728</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>84759322500018</td>\n",
       "      <td>{\"top_ads\": [], \"meta_data\": {\"url\": \"https://...</td>\n",
       "      <td>2023-09-20 10:56:36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           keyword            SIRET  \\\n",
       "0     1999                      \"actualitÃ©s\"  408627354 00124   \n",
       "1      372                      \"actualitÃ©s\"   34899155500353   \n",
       "2      371                      \"actualitÃ©s\"   30649449300050   \n",
       "3      370                      \"actualitÃ©s\"   31124863700804   \n",
       "4      369                      \"actualitÃ©s\"   37755024900041   \n",
       "...    ...                               ...              ...   \n",
       "1899  1732  \"partenariat\" OR \"collaboration\"   34963839500021   \n",
       "1900  1731  \"partenariat\" OR \"collaboration\"   31647330500035   \n",
       "1901  1730  \"partenariat\" OR \"collaboration\"   84529824900028   \n",
       "1902  1729  \"partenariat\" OR \"collaboration\"   33105740600067   \n",
       "1903  1728  \"partenariat\" OR \"collaboration\"   84759322500018   \n",
       "\n",
       "                                         google_results         scraped_date  \\\n",
       "0                                                   NaN  2024-03-03 07:02:38   \n",
       "1     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:31   \n",
       "2     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:27   \n",
       "3     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:23   \n",
       "4     {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:39:24   \n",
       "...                                                 ...                  ...   \n",
       "1899  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:31   \n",
       "1900  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:30   \n",
       "1901  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:47   \n",
       "1902  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:37   \n",
       "1903  {\"top_ads\": [], \"meta_data\": {\"url\": \"https://...  2023-09-20 10:56:36   \n",
       "\n",
       "      scraped  \n",
       "0         NaN  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "...       ...  \n",
       "1899      1.0  \n",
       "1900      1.0  \n",
       "1901      1.0  \n",
       "1902      1.0  \n",
       "1903      1.0  \n",
       "\n",
       "[1904 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee593cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"actualitÃ©s\"\n",
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"annonce\"\n",
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"controverses\" OR \"problÃ¨me\" OR \"litige\"\n",
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"Ã©vÃ©nement\" OR \"sÃ©minaire\" OR \"atelier\"\n",
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"lancement de produit\" OR \"nouveau service\"\n",
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"nomination\" OR \"dÃ©part\" OR \"nouveau dirigeant\"\n",
      "Erreur : json_str n'est pas une chaÃ®ne. SIRET: 408627354 00124, Keyword: \"partenariat\" OR \"collaboration\"\n"
     ]
    }
   ],
   "source": [
    "def extraire_donnees(json_str, siret, keyword):\n",
    "    try:\n",
    "        # Assurez-vous que json_str est une chaÃ®ne\n",
    "        if not isinstance(json_str, str):\n",
    "            print(f\"Erreur : json_str n'est pas une chaÃ®ne. SIRET: {siret}, Keyword: {keyword}\")\n",
    "            return []\n",
    "\n",
    "        # Charger la chaÃ®ne JSON en dictionnaire\n",
    "        data = json.loads(json_str)\n",
    "        results = []\n",
    "        \n",
    "        # ItÃ©ration sur les rÃ©sultats organiques\n",
    "        for result in data.get('organic_results', []):\n",
    "            res_dict = {\n",
    "                'siret': siret,\n",
    "                'keyword': keyword,\n",
    "                'url': result.get('url', ''),\n",
    "                'title': result.get('title', ''),\n",
    "                'domain': result.get('domain', ''),\n",
    "                'description': result.get('description', ''),\n",
    "                'displayed_url': result.get('displayed_url', '')\n",
    "            }\n",
    "            if isinstance(result.get('sitelinks'), dict):\n",
    "                res_dict['sitelinks'] = result.get('sitelinks', {}).get('expanded', [])\n",
    "            else:\n",
    "                res_dict['sitelinks'] = []\n",
    "            results.append(res_dict)\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction: {e}, siret: {siret}, keyword: {keyword}\")\n",
    "        return []\n",
    "    \n",
    "resultats_extraits = []\n",
    "\n",
    "# ItÃ©rer sur chaque ligne du DataFrame data_modifie\n",
    "for idx, row in data_modifie.iterrows():\n",
    "    # Extraire les donnÃ©es organiques, le siret et le mot-clÃ© pour chaque ligne\n",
    "    resultats_temp = extraire_donnees(row['google_results'], row['SIRET'], row['keyword'])\n",
    "    # Ajouter les rÃ©sultats Ã  la liste principale\n",
    "    resultats_extraits.extend(resultats_temp)\n",
    "\n",
    "# Convertir la liste des rÃ©sultats extraits en un nouveau DataFrame\n",
    "detail_google_search = pd.DataFrame(resultats_extraits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a53f7aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siret</th>\n",
       "      <th>keyword</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "      <th>description</th>\n",
       "      <th>displayed_url</th>\n",
       "      <th>sitelinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>https://www.nicematin.com/conso-shopping/le-pl...</td>\n",
       "      <td>Le plus grand Zara de la rÃ©gion Sud a ouvert c...</td>\n",
       "      <td>www.nicematin.com</td>\n",
       "      <td>May 4, 2023 â€” Nice-Matin. Se connecter Â· Abonn...</td>\n",
       "      <td>https://www.nicematin.com â€º le-plu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>https://nicepresse.com/le-plus-grand-zara-de-t...</td>\n",
       "      <td>Le plus grand Zara de tout le Sud-Est bientÃ´t ...</td>\n",
       "      <td>nicepresse.com</td>\n",
       "      <td>Oct 31, 2022 â€” Nice-Presse : actualitÃ©s et inf...</td>\n",
       "      <td>https://nicepresse.com â€º le-plus-gra...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>https://actu.fr/provence-alpes-cote-d-azur/nic...</td>\n",
       "      <td>Nice. Pourquoi y avait-il une grosse file d'at...</td>\n",
       "      <td>actu.fr</td>\n",
       "      <td>Nov 25, 2022 â€” DerniÃ¨res actualitÃ©s. Actu Nice...</td>\n",
       "      <td>https://actu.fr â€º nice_06088 â€º nice-...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>https://actu.fr/provence-alpes-cote-d-azur/sai...</td>\n",
       "      <td>PrÃ¨s de Nice, CAP 3000 annonce de nouvelles bo...</td>\n",
       "      <td>actu.fr</td>\n",
       "      <td>Jan 19, 2023 â€” L'un des plus grands Zara de Fr...</td>\n",
       "      <td>https://actu.fr â€º pres-de-nice-cap-30...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34899155500353</td>\n",
       "      <td>\"actualitÃ©s\"</td>\n",
       "      <td>https://www.lefigaro.fr/tag/zara</td>\n",
       "      <td>Zara : derniÃ¨res actualitÃ©s et vidÃ©os</td>\n",
       "      <td>www.lefigaro.fr</td>\n",
       "      <td>Les derniÃ¨res actualitÃ©s sur Zara.</td>\n",
       "      <td>https://www.lefigaro.fr â€º tag â€º zara</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13930</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=9QIdYbTIKQAC&amp;...</td>\n",
       "      <td>Le MÃ©morial diplomatique</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... AAA Vient de Paraitre chez PAUL OLLENDORFF...</td>\n",
       "      <td>https://books.google.fr â€º books</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13931</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=PbKXBAAAQBAJ&amp;...</td>\n",
       "      <td>Michelin Green Guide France - Google Books Result</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... collaboration with Coysevox and Tuby. In t...</td>\n",
       "      <td>https://books.google.fr â€º books</td>\n",
       "      <td>[{'link': '/search?num=100&amp;sca_esv=566872717&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13932</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=CjiXEAAAQBAJ&amp;...</td>\n",
       "      <td>Sekiro: La seconde vie des Souls - Google Book...</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... partenariat avec Activision en surprend â€“ ...</td>\n",
       "      <td>https://books.google.fr â€º books</td>\n",
       "      <td>[{'link': '/search?num=100&amp;sca_esv=566872717&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13933</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=qZZ-CwAAQBAJ&amp;...</td>\n",
       "      <td>Robert Trent Jones Golf Trail: Its History and...</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... collaboration between the City of Montgome...</td>\n",
       "      <td>https://books.google.fr â€º books</td>\n",
       "      <td>[{'link': '/search?num=100&amp;sca_esv=566872717&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>84759322500018</td>\n",
       "      <td>\"partenariat\" OR \"collaboration\"</td>\n",
       "      <td>https://books.google.fr/books?id=PYY9AQAAMAAJ&amp;...</td>\n",
       "      <td>Bulletin du ComitÃ© de l'Asie franÃ§aise</td>\n",
       "      <td>books.google.fr</td>\n",
       "      <td>... coiffure sur leur tÃªte rasÃ©e un volumineux...</td>\n",
       "      <td>https://books.google.fr â€º books</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13935 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                siret                           keyword  \\\n",
       "0      34899155500353                      \"actualitÃ©s\"   \n",
       "1      34899155500353                      \"actualitÃ©s\"   \n",
       "2      34899155500353                      \"actualitÃ©s\"   \n",
       "3      34899155500353                      \"actualitÃ©s\"   \n",
       "4      34899155500353                      \"actualitÃ©s\"   \n",
       "...               ...                               ...   \n",
       "13930  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13931  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13932  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13933  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "13934  84759322500018  \"partenariat\" OR \"collaboration\"   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.nicematin.com/conso-shopping/le-pl...   \n",
       "1      https://nicepresse.com/le-plus-grand-zara-de-t...   \n",
       "2      https://actu.fr/provence-alpes-cote-d-azur/nic...   \n",
       "3      https://actu.fr/provence-alpes-cote-d-azur/sai...   \n",
       "4                       https://www.lefigaro.fr/tag/zara   \n",
       "...                                                  ...   \n",
       "13930  https://books.google.fr/books?id=9QIdYbTIKQAC&...   \n",
       "13931  https://books.google.fr/books?id=PbKXBAAAQBAJ&...   \n",
       "13932  https://books.google.fr/books?id=CjiXEAAAQBAJ&...   \n",
       "13933  https://books.google.fr/books?id=qZZ-CwAAQBAJ&...   \n",
       "13934  https://books.google.fr/books?id=PYY9AQAAMAAJ&...   \n",
       "\n",
       "                                                   title             domain  \\\n",
       "0      Le plus grand Zara de la rÃ©gion Sud a ouvert c...  www.nicematin.com   \n",
       "1      Le plus grand Zara de tout le Sud-Est bientÃ´t ...     nicepresse.com   \n",
       "2      Nice. Pourquoi y avait-il une grosse file d'at...            actu.fr   \n",
       "3      PrÃ¨s de Nice, CAP 3000 annonce de nouvelles bo...            actu.fr   \n",
       "4                  Zara : derniÃ¨res actualitÃ©s et vidÃ©os    www.lefigaro.fr   \n",
       "...                                                  ...                ...   \n",
       "13930                           Le MÃ©morial diplomatique    books.google.fr   \n",
       "13931  Michelin Green Guide France - Google Books Result    books.google.fr   \n",
       "13932  Sekiro: La seconde vie des Souls - Google Book...    books.google.fr   \n",
       "13933  Robert Trent Jones Golf Trail: Its History and...    books.google.fr   \n",
       "13934             Bulletin du ComitÃ© de l'Asie franÃ§aise    books.google.fr   \n",
       "\n",
       "                                             description  \\\n",
       "0      May 4, 2023 â€” Nice-Matin. Se connecter Â· Abonn...   \n",
       "1      Oct 31, 2022 â€” Nice-Presse : actualitÃ©s et inf...   \n",
       "2      Nov 25, 2022 â€” DerniÃ¨res actualitÃ©s. Actu Nice...   \n",
       "3      Jan 19, 2023 â€” L'un des plus grands Zara de Fr...   \n",
       "4                     Les derniÃ¨res actualitÃ©s sur Zara.   \n",
       "...                                                  ...   \n",
       "13930  ... AAA Vient de Paraitre chez PAUL OLLENDORFF...   \n",
       "13931  ... collaboration with Coysevox and Tuby. In t...   \n",
       "13932  ... partenariat avec Activision en surprend â€“ ...   \n",
       "13933  ... collaboration between the City of Montgome...   \n",
       "13934  ... coiffure sur leur tÃªte rasÃ©e un volumineux...   \n",
       "\n",
       "                                  displayed_url  \\\n",
       "0         https://www.nicematin.com â€º le-plu...   \n",
       "1       https://nicepresse.com â€º le-plus-gra...   \n",
       "2       https://actu.fr â€º nice_06088 â€º nice-...   \n",
       "3      https://actu.fr â€º pres-de-nice-cap-30...   \n",
       "4          https://www.lefigaro.fr â€º tag â€º zara   \n",
       "...                                         ...   \n",
       "13930           https://books.google.fr â€º books   \n",
       "13931           https://books.google.fr â€º books   \n",
       "13932           https://books.google.fr â€º books   \n",
       "13933           https://books.google.fr â€º books   \n",
       "13934           https://books.google.fr â€º books   \n",
       "\n",
       "                                               sitelinks  \n",
       "0                                                     []  \n",
       "1                                                     []  \n",
       "2                                                     []  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "13930                                                 []  \n",
       "13931  [{'link': '/search?num=100&sca_esv=566872717&g...  \n",
       "13932  [{'link': '/search?num=100&sca_esv=566872717&g...  \n",
       "13933  [{'link': '/search?num=100&sca_esv=566872717&g...  \n",
       "13934                                                 []  \n",
       "\n",
       "[13935 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_google_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2450e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez des colonnes pour le rÃ©sumÃ© et la date dans le DataFrame\n",
    "detail_google_search['resume'] = pd.NA\n",
    "detail_google_search['date'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1282e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DÃ©couper le DataFrame en sous-ensembles en tenant compte des changements de SIRET\n",
    "start_idx = 0  # Index de dÃ©part pour la tranche actuelle\n",
    "for i in range(taille_chunk, len(detail_google_search_sorted) + taille_chunk, taille_chunk):\n",
    "    # Trouver la fin de la tranche en s'assurant que tous les enregistrements d'un SIRET sont ensemble\n",
    "    # Si on n'est pas Ã  la fin du DataFrame\n",
    "    if i < len(detail_google_search_sorted):\n",
    "        while (i < len(detail_google_search_sorted) and \n",
    "               detail_google_search_sorted.iloc[i - 1]['siret'] == detail_google_search_sorted.iloc[i]['siret']):\n",
    "            i += 1  # DÃ©placer l'index de fin jusqu'Ã  ce qu'on trouve un nouveau SIRET\n",
    "    \n",
    "    # DÃ©couper le DataFrame jusqu'Ã  cet indice\n",
    "    dfs.append(detail_google_search_sorted[start_idx:i])\n",
    "    \n",
    "    # Mettre Ã  jour l'index de dÃ©part pour la prochaine tranche\n",
    "    start_idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b88b6728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tranches crÃ©Ã©es : 5\n",
      "tranche 1 : 2795\n",
      "tranche 2 : 2932\n",
      "tranche 3 : 2639\n",
      "tranche 4 : 2784\n",
      "tranche 5 : 2785\n",
      "total: 13935\n"
     ]
    }
   ],
   "source": [
    "nombre_tranches = len(dfs)-1\n",
    "print(f\"Nombre de tranches crÃ©Ã©es : {nombre_tranches}\")\n",
    "print(f\"tranche 1 : {len(dfs[1])}\")\n",
    "print(f\"tranche 2 : {len(dfs[2])}\")\n",
    "print(f\"tranche 3 : {len(dfs[3])}\")\n",
    "print(f\"tranche 4 : {len(dfs[4])}\")\n",
    "print(f\"tranche 5 : {len(dfs[5])}\")\n",
    "print(f\"total: {len(dfs[1])+len(dfs[2])+len(dfs[3])+len(dfs[4])+len(dfs[5])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0d4fd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_et_resume(url):\n",
    "    attempts = 0\n",
    "    while attempts < 1:  # une tentative\n",
    "        try:\n",
    "            # Effectuer une requÃªte GET sur le site\n",
    "            response = requests.get(url, timeout=10)  # Augmentez le timeout si nÃ©cessaire\n",
    "            # CrÃ©er un objet BeautifulSoup pour analyser le HTML\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extraire le texte souhaitÃ©, par exemple, tous les paragraphes\n",
    "            text = ' '.join(p.text for p in soup.find_all('p'))\n",
    "\n",
    "            # Recherche de la date dans les mÃ©tadonnÃ©es\n",
    "            meta_date = soup.find('meta', {'property': 'article:published_time'})\n",
    "            if meta_date:\n",
    "                date = meta_date['content']\n",
    "            else:\n",
    "                # Ajoutez le nouveau motif pour les dates avec mois en lettres\n",
    "                date_patterns = [\n",
    "                    r'\\b\\d{4}-\\d{2}-\\d{2}\\b',\n",
    "                    r'\\b\\d{2}/\\d{2}/\\d{4}\\b',\n",
    "                    r'\\b\\d{2}-\\d{2}-\\d{4}\\b',\n",
    "                    # Motif pour le format \"14 octobre 2023\" ou \"14 Octobre 2023\"\n",
    "                    r'\\b\\d{1,2}\\s(?:janvier|fÃ©vrier|mars|avril|mai|juin|juillet|aoÃ»t|septembre|octobre|novembre|dÃ©cembre)\\s\\d{4}\\b',\n",
    "                    r'\\b\\d{1,2}\\s(?:Janvier|FÃ©vrier|Mars|Avril|Mai|Juin|Juillet|AoÃ»t|Septembre|Octobre|Novembre|DÃ©cembre)\\s\\d{4}\\b'\n",
    "                ]\n",
    "                date = 'Date non trouvÃ©e'\n",
    "                for pattern in date_patterns:\n",
    "                    match = re.search(pattern, text, re.IGNORECASE)  # Utiliser IGNORECASE pour ne pas se soucier de la casse\n",
    "                    if match:\n",
    "                        date = match.group()\n",
    "                        break\n",
    "\n",
    "            # CrÃ©ation d'un rÃ©sumÃ© du texte\n",
    "            parser = PlaintextParser.from_string(text, Tokenizer('french'))\n",
    "            summarizer = Summarizer()\n",
    "            resume_text = ' '.join(str(sentence) for sentence in summarizer(parser.document, 10))\n",
    "            return resume_text, date\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            attempts += 1\n",
    "            time.sleep(5)  # DÃ©lai entre les tentatives\n",
    "    \n",
    "    # Retourner None si toutes les tentatives Ã©chouent\n",
    "    return None, None\n",
    "\n",
    "def analyze_sentiment(sentence):\n",
    "    analysis = TextBlob(sentence)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positif'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutre'\n",
    "    else:\n",
    "        return 'NÃ©gatif'\n",
    "    \n",
    "# Fonction pour convertir les sentiments en poids\n",
    "def sentiment_to_weight(sentiment):\n",
    "    weights = {'Positif': 1, 'Neutre': 0, 'NÃ©gatif': -1}\n",
    "    return weights.get(sentiment, 0)  # Retourne 0 si le sentiment n'est pas reconnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386412a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traiter_dataframe(df):\n",
    "    # fonction de parralelisation\n",
    "    \n",
    "    print(f\"Traitement du DataFrame de taille {len(df)}\")\n",
    "    \n",
    "    # RÃ©initialise l'index du DataFrame pour une itÃ©ration propre (df_index(drop=True) devrait Ãªtre df.reset_index(drop=True) \n",
    "    # pour fonctionner correctement).\n",
    "    df = df_index(drop=True)\n",
    "    \n",
    "    # Calcul du total des lignes et du point de contrÃ´le pour suivre la progression du traitement, en dÃ©coupant le DataFrame en dix segments (10 % chacun) \n",
    "    # pour les rapports d'avancement.\n",
    "    total_lignes = len(df)\n",
    "    print(total_lignes)\n",
    "    pourcent = total_lignes / 10\n",
    "    compteur=0\n",
    "    \n",
    "    # ItÃ¨re sur chaque ligne du DataFrame pour exÃ©cuter scraper_et_resume sur l'URL de chaque ligne. \n",
    "    # Met Ã  jour le DataFrame avec les nouveaux rÃ©sumÃ©s et dates rÃ©cupÃ©rÃ©s, Ã  condition que le rÃ©sumÃ© ne soit pas vide.\n",
    "    for index, row in df.iterrows():\n",
    "    try:\n",
    "        resume, date = scraper_et_resume(row['url'])\n",
    "        # VÃ©rifiez si le rÃ©sumÃ© est vide avant de mettre Ã  jour le DataFrame\n",
    "        if resume:  # Si 'resume' n'est pas vide\n",
    "            df.at[index, 'resume'] = resume\n",
    "            df.at[index, 'date'] = date\n",
    "        else:  \n",
    "            print(f\"Contenu vide pour l'URL {row['url']} Ã  la ligne {index}, pas de mise Ã  jour.\")\n",
    "            continue  # Passe Ã  l'itÃ©ration suivante sans mettre Ã  jour les valeurs dans le DataFrame\n",
    "    # GÃ¨re les exceptions qui peuvent survenir pendant le processus de scraping, permettant Ã  la boucle de continuer mÃªme en cas d'erreur.        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de la ligne {index}: {e}\")\n",
    "        continue  # Passe Ã  l'itÃ©ration suivante en cas d'erreur\n",
    "    \n",
    "    print(f\"Avancement: {math.ceil((compteur / total_lignes) * 100)}% terminÃ©.\")\n",
    "    compteur+=1\n",
    "    \n",
    "    # Supprime les lignes oÃ¹ la colonne 'date' est NaN aprÃ¨s le scraping pour assurer l'intÃ©gritÃ© des donnÃ©es et remplace \n",
    "    # les chaÃ®nes \"Date non trouvÃ©e\" par NaN, puis convertit les chaÃ®nes de date restantes en objets datetime, \n",
    "    #en gÃ©rant les erreurs et en supprimant le fuseau horaire pour uniformitÃ©.\n",
    "    df = df.dropna(subset=['date'])\n",
    "\n",
    "    # Remplacer \"Date non trouvÃ©e\" par NaN puis convertir les chaÃ®nes de date en objets datetime\n",
    "    df['date'] = df['date'].replace('Date non trouvÃ©e', pd.NA)\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "\n",
    "    # Obtenir la date du jour en UTC pour garder la cohÃ©rence avec les autres dates\n",
    "    date_du_jour = pd.Timestamp('now', tz='UTC')\n",
    "\n",
    "    # Remplacer les valeurs NaN par la date du jour en format UTC\n",
    "    df['date'] = df['date'].fillna(date_du_jour)\n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "\n",
    "    # Extraire l'annÃ©e de la colonne de date\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Appliquer la fonction analyze_sentiment Ã  chaque rÃ©sumÃ© dans le DataFrame\n",
    "    df['sentiment'] = df['resume'].apply(analyze_sentiment)\n",
    "    \n",
    "    # Convertir les dates en datetime et extraire l'annÃ©e\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    # Appliquer la fonction pour convertir les sentiments en poids\n",
    "    df['sentiment_weight'] = df['sentiment'].apply(sentiment_to_weight)\n",
    "\n",
    "    # Calculer la moyenne pondÃ©rÃ©e des sentiments par annÃ©e\n",
    "    weighted_average_by_year = df.groupby('year')['sentiment_weight'].mean()\n",
    "    \n",
    "    # Calculer la moyenne pondÃ©rÃ©e des sentiments par annÃ©e et par SIRET\n",
    "    grouped = df.groupby(['siret', 'year'])['sentiment_weight'].mean().reset_index()\n",
    "\n",
    "    # Pivoter pour obtenir les annÃ©es en colonnes et les SIRETs en lignes\n",
    "    pivot_table = grouped.pivot(index='siret', columns='year', values='sentiment_weight')\n",
    "\n",
    "    # Renommer les colonnes pour le format souhaitÃ©\n",
    "    pivot_table.columns = [f'sentiment weight an{year}' for year in pivot_table.columns]\n",
    "\n",
    "    # RÃ©initialiser l'index pour obtenir 'siret' comme une colonne\n",
    "    final_output = pivot_table.reset_index()\n",
    "\n",
    "    # Afficher le DataFrame final\n",
    "    print(final_output)\n",
    "    \n",
    "        return df, final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de ThreadPoolExecutor pour parallÃ©liser le traitement\n",
    "\n",
    "dfs_adaptes = []  # Liste pour stocker tous les DataFrames adaptÃ©s\n",
    "dfs_final_output = []  # Liste pour stocker tous les DataFrames final_output\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Planifier l'exÃ©cution de la fonction de traitement pour chaque sous-DataFrame\n",
    "    futures = [executor.submit(traiter_dataframe, df) for df in dfs]\n",
    "\n",
    "    # Attendre que tous les futurs soient terminÃ©s et recueillir les rÃ©sultats\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        df_adapte, final_out = future.result()\n",
    "        dfs_adaptes.append(df_adapte)\n",
    "        dfs_final_output.append(final_out)\n",
    "\n",
    "# Fusionner tous les DataFrames adaptÃ©s en un seul\n",
    "data_google_search = pd.concat(dfs_adaptes)\n",
    "\n",
    "# Fusionner tous les final_output en un seul\n",
    "global_final_output = pd.concat(dfs_final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02670178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir la date actuelle\n",
    "date_actuelle = datetime.now().strftime('%Y-%m-%d')  # Formate la date comme \"AAAA-MM-JJ\"\n",
    "\n",
    "# CrÃ©er le nom du fichier avec la date\n",
    "nom_fichier = f\"search_Google_{date_actuelle}_actu_resumÃ©.csv\"\n",
    "\n",
    "# Exporter le DataFrame en CSV\n",
    "data_google_search.to_csv(nom_fichier, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#referentiel base source\n",
    "source_entreprise=pd.read_csv('base_source_enrichie.csv', encoding='utf-8', sep=',', on_bad_lines='skip')\n",
    "source_entreprise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55928f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les DataFrames  base enrichie et final output sur la colonne 'siret'\n",
    "df_enrichie = pd.merge(source_entreprise, global_final_output, on='siret', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa709da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter le DataFrame en CSV\n",
    "nom-fichier='base_source_enrichie.csv'\n",
    "df_enrichie.to_csv(nom_fichier, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c48743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
